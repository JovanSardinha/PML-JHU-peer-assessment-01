confusionMatrix(diagnosis, predict(modelFit, testPC))
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC), data = training2)
confusionMatrix.default(testing2$diagnosis, predict(modelFit, testPC))
confusionMatrix.default(testing2$diagnosis, predict(modelFit, testPC))
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
debug
debug(confusionMatrix(testing2$diagnosis, predict(modelFit, testPC)))
showerror
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
library(caret); library(kernlab); data(spam)
install.packages("kernlab")
library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.80)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1])
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
install.packages('e1071', dependencies=TRUE)
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.80)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.80)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.80)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
availablePackages <- available.packages()[,1]
install.packages(availablePackages)
installedPackages <- .packages(all.available = TRUE)
install.packages('e1071', dependencies=TRUE)
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training2$diagnosis ~., method = "glm", data = trainPC)
testPC <- predict(preProc, testing2[,-1])
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
library(caret)
library(AppliedPredictiveModeling)
library(e1071)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training2 <- training[,c(1,grep("^IL", colnames(training)))]
testing2 <- testing[,c(1,grep("^IL", colnames(testing)))]
preProc <- preProcess(training2[,-1], method = "pca", thresh = 0.90)
trainPC <- predict(preProc, training2[-1])
modelFit <- train(training2$diagnosis ~., method = "glm", data = trainPC)
confusionMatrix(testing2$diagnosis, predict(modelFit, testPC))
confusionMatrix(testing2$diagnosis, predict(modelFit, testing2))
data(iris); library(ggplot2)
library(caret)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit$finalModel
getTree(modFit$finalModel, k=2)
data(iris); library(ggplot2)
library(caret)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit$finalModel
getTree(modFit$finalModel, k=2)
######
wd <- "C:/Users/jsardinha/Documents/GitHub/PML_JHU_PeerAssessment_01"
setwd(wd)
library(RCurl)
library(knitr)
library(caret)
library(ggplot2)
library(corrplot)
library(randomForest)
wd <- "C:/Users/jsardinha/Documents/GitHub/PML_JHU_PeerAssessment_01"
setwd(wd)
library(RCurl)
library(knitr)
library(caret)
library(ggplot2)
library(corrplot)
library(randomForest)
if(!file.exists("./data")){dir.create("./data")}
trainDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- paste("./data/", basename(trainDataURL), sep = "")
download.file(trainDataURL, trainFile, method = "curl")
# Downloading Testing Data
if(!file.exists("./data")){dir.create("./data")}
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- paste("./data/", basename(testDataURL), sep = "")
download.file(testDataURL, testFile, method = "curl")
trainData <- read.csv(trainFile)
testData <- read.csv(testFile)
toMatch <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window")
removeColumns <- grep(paste(toMatch,collapse="|"), colnames(trainData))
#Removing Zero Varience Values (provide more specific reason)
nzv <- nearZeroVar(trainData, saveMetrics = TRUE)
removeColumns <- c(removeColumns,which(nzv$nzv == TRUE))
#Removing aggregate data, characterized by NA
AggregateVals <- names(trainData[,colSums(is.na(trainData), na.rm = FALSE) > 0.95*nrow(trainData)])
NAColumns <- grep(paste(AggregateVals,collapse="|"), colnames(trainData))
removeColumns <- c(removeColumns,NAColumns)
#Removind Uniques only
removeColumns <- unique(removeColumns)
#Preparing Tidy Data Sets
trainDataTidy <- trainData[,-removeColumns]
testDataTidy <- testData[,-removeColumns] # Try to see if this works without removing cols
## Preparing CV Data Set
set.seed(1123)
inCV <- createDataPartition(y=trainDataTidy$classe,
p=0.6, list=FALSE)
training <- trainDataTidy[inCV,]
crossVal <- trainDataTidy[-inCV,]
# This above split is in line with Andrew Ng
# Storing prediction value column number
classeCol <- grep("classe", colnames(training))
trainCorr <- cor(training[,-classeCol])
trainCorr <- round(trainCorr, digits=2)
#All gyros are very coorelated
corrplot(trainCorr, method = "square", order="hclust", tl.cex=0.55, tl.srt=90)
corrplot(trainCorr, method = "square", order="FPC", tl.cex=0.55, tl.srt=90) # That as usefull as the previous graph
set.seed(1123)
confusionMatrix(crossVal$classe, predict(modelFit_rf, crossVal))
modelFit_rf <- train(classe~ ., method = "rf", data = training, prox=TRUE)
removeNames <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window","problem_id")
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
namesFeatures <- namesFeatures[ -which(namesFeatures %in% removeNames)] # Remove non-feature
removeNames <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window","problem_id")
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
namesFeatures <- namesFeatures[ -which(namesFeatures %in% removeNames)] # Remove non-feature
dfTidyTrain <- dfRawTrain[, c("classe", namesFeatures)] # dim=19622,53
dfTidyTest <- dfRawTest[, c("problem_id", namesFeatures)] # dim=20,53
set.seed(42)
idxSample <- createDataPartition(y=dfTidyTrain$classe, p=0.30, list=FALSE)
dfTrain <- dfTidyTrain[idxSample,] # dim=5889,53
dfCross <- dfTidyTrain[-idxSample,] # dim=13733,53
dfTest <- dfTidyTest # dim=20,53
rm(dfRawTrain)
rm(dfRawTest)
rm(dfTidyTrain)
rm(dfTidyTest)
set.seed(1123)
modelFit_rf <- train(classe~ ., method = "rf", data = dfTrain, prox=TRUE)
idxSample <- createDataPartition(y=dfTidyTrain$classe, p=0.30, list=FALSE)
removeNames <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window","problem_id")
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
if(!file.exists("./data")){dir.create("./data")}
trainDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- paste("./data/", basename(trainDataURL), sep = "")
download.file(trainDataURL, trainFile, method = "curl")
# Downloading Testing Data
if(!file.exists("./data")){dir.create("./data")}
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- paste("./data/", basename(testDataURL), sep = "")
download.file(testDataURL, testFile, method = "curl")
dfRawTrain <- read.csv("./data/pml-training.csv", sep=",") # dim=19622,160
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
dfRawTrain <- read.csv("./data/pml-training.csv", sep=",") # dim=19622,160
dfRawTest <- read.csv("./data/pml-testing.csv", sep=",") # dim=20,160
removeNames <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window","problem_id")
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
namesFeatures <- namesFeatures[ -which(namesFeatures %in% removeNames)] # Remove non-feature
dfTidyTrain <- dfRawTrain[, c("classe", namesFeatures)] # dim=19622,53
dfTidyTest <- dfRawTest[, c("problem_id", namesFeatures)] # dim=20,53
set.seed(42)
idxSample <- createDataPartition(y=dfTidyTrain$classe, p=0.30, list=FALSE)
dfTrain <- dfTidyTrain[idxSample,] # dim=5889,53
dfCross <- dfTidyTrain[-idxSample,] # dim=13733,53
dfTest <- dfTidyTest # dim=20,53
rm(dfRawTrain)
rm(dfRawTest)
rm(dfTidyTrain)
rm(dfTidyTest)
set.seed(1123)
modelFit_rf <- train(classe~ ., method = "rf", data = dfTrain, prox=TRUE)
warnings()
modelFit_rf <- train(classe~ ., method = "rf", data = dfTrain[1:30,], prox=TRUE)
warnings()
modelFit_rf <- train(classe~ ., method = "rf", preProcess = "pca", data = dfTrain[1:30,], prox=TRUE)
modelFit_rf <- train(classe~ ., method = "rf", preProcess = "pca", data = training[1:30,], prox=TRUE)
modelFit_gbm <- train(classe ~ ., method="gbm",data=training[1:30,],verbose=FALSE)
wd <- "C:/Users/jsardinha/Documents/GitHub/PML_JHU_PeerAssessment_01"
setwd(wd)
library(RCurl)
library(knitr)
library(caret)
library(ggplot2)
library(corrplot)
library(randomForest)
# Downloading Training Data
if(!file.exists("./data")){dir.create("./data")}
trainDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- paste("./data/", basename(trainDataURL), sep = "")
download.file(trainDataURL, trainFile, method = "curl")
# Downloading Testing Data
if(!file.exists("./data")){dir.create("./data")}
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- paste("./data/", basename(testDataURL), sep = "")
download.file(testDataURL, testFile, method = "curl")
# Importing Data
trainData <- read.csv(trainFile)
testData <- read.csv(testFile)
toMatch <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window")
jovan <- c(1,2,3,4,5,6,6,7,8)
rm(jovan)
toMatch <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window")
removeColumns <- grep(paste(toMatch,collapse="|"), colnames(trainData))
nzv <- nearZeroVar(trainData, saveMetrics = TRUE)
removeColumns <- c(removeColumns,which(nzv$nzv == TRUE))
#Removing aggregate data, characterized by NA
AggregateVals <- names(trainData[,colSums(is.na(trainData), na.rm = FALSE) > 0.95*nrow(trainData)])
NAColumns <- grep(paste(AggregateVals,collapse="|"), colnames(trainData))
removeColumns <- c(removeColumns,NAColumns)
removeColumns
?uique
?unique
if(!file.exists("./data")){dir.create("./data")}
trainDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- paste("./data/", basename(trainDataURL), sep = "")
download.file(trainDataURL, trainFile, method = "curl")
# Downloading Testing Data
if(!file.exists("./data")){dir.create("./data")}
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- paste("./data/", basename(testDataURL), sep = "")
download.file(testDataURL, testFile, method = "curl")
dfRawTrain <- read.csv("./data/pml-training.csv", sep=",") # dim=19622,160
dfRawTest <- read.csv("./data/pml-testing.csv", sep=",") # dim=20,160
removeNames <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window","problem_id")
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
namesFeatures <- namesFeatures[ -which(namesFeatures %in% removeNames)] # Remove non-feature
nameFeatures
namesFeatures
grep(namesFeatures, colnames(dfRawTrain))
grep(paste(namesFeatures,collapse="|"), colnames(dfRawTrain))
count(grep(paste(namesFeatures,collapse="|"), colnames(dfRawTrain)))
count(removeColumns)
dfTidyTest <- dfRawTest[, c("problem_id", namesFeatures)] # dim=20,53
set.seed(42)
idxSample <- createDataPartition(y=dfTidyTrain$classe, p=0.30, list=FALSE)
dfTrain <- dfTidyTrain[idxSample,] # dim=5889,53
dfCross <- dfTidyTrain[-idxSample,] # dim=13733,53
dfTest <- dfTidyTest # dim=20,53
dfRawTrain <- read.csv("./data/pml-training.csv", sep=",") # dim=19622,160
dfRawTest <- read.csv("./data/pml-testing.csv", sep=",") # dim=20,160
removeNames <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window","problem_id")
namesFeatures <- names(dfRawTest[,colSums(is.na(dfRawTest)) != nrow(dfRawTest)]) # Remove columns with NA
namesFeatures <- namesFeatures[ -which(namesFeatures %in% removeNames)] # Remove non-feature
dfTidyTrain <- dfRawTrain[, c("classe", namesFeatures)] # dim=19622,53
dfTidyTest <- dfRawTest[, c("problem_id", namesFeatures)] # dim=20,53
set.seed(42)
idxSample <- createDataPartition(y=dfTidyTrain$classe, p=0.30, list=FALSE)
dfTrain <- dfTidyTrain[idxSample,] # dim=5889,53
dfCross <- dfTidyTrain[-idxSample,] # dim=13733,53
dfTest <- dfTidyTest # dim=20,53
rm(dfRawTrain)
rm(dfRawTest)
rm(dfTidyTrain)
rm(dfTidyTest)
if(!file.exists("./data")){dir.create("./data")}
trainDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- paste("./data/", basename(trainDataURL), sep = "")
download.file(trainDataURL, trainFile, method = "curl")
# Downloading Testing Data
if(!file.exists("./data")){dir.create("./data")}
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- paste("./data/", basename(testDataURL), sep = "")
download.file(testDataURL, testFile, method = "curl")
trainData <- read.csv(trainFile)
testData <- read.csv(testFile)
# #Adding original values
# trainData$OriginalRows <- row.names(trainData)
##Cleaning the traning data set
#Removing user specific data (provide more concrete reason)
toMatch <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window")
removeColumns <- grep(paste(toMatch,collapse="|"), colnames(trainData))
#Removing Zero Varience Values (provide more specific reason)
nzv <- nearZeroVar(trainData, saveMetrics = TRUE)
removeColumns <- c(removeColumns,which(nzv$nzv == TRUE))
#Removing aggregate data, characterized by NA
AggregateVals <- names(trainData[,colSums(is.na(trainData), na.rm = FALSE) > 0.95*nrow(trainData)])
NAColumns <- grep(paste(AggregateVals,collapse="|"), colnames(trainData))
removeColumns <- c(removeColumns,NAColumns)
#Removind Uniques only
removeColumns <- unique(removeColumns)
#Preparing Tidy Data Sets
trainDataTidy <- trainData[,-removeColumns]
testDataTidy <- testData[,-removeColumns] # Try to see if this works without removing cols
## Preparing CV Data Set
set.seed(1123)
inCV <- createDataPartition(y=trainDataTidy$classe,
p=0.6, list=FALSE)
training <- trainDataTidy[inCV,]
crossVal <- trainDataTidy[-inCV,]
# This above split is in line with Andrew Ng
# Storing prediction value column number
classeCol <- grep("classe", colnames(training))
trainCorr <- cor(training[,-classeCol])
trainCorr <- round(trainCorr, digits=2)
#All gyros are very coorelated
corrplot(trainCorr, method = "square", order="hclust", tl.cex=0.55, tl.srt=90)
corrplot(trainCorr, method = "square", order="FPC", tl.cex=0.55, tl.srt=90) # That as usefull as the previous graph
write.csv(training, file = "training.csv")
write.csv(training, file = "training.csv")
wd <- "C:/Users/jsardinha/Documents/GitHub/PML_JHU_PeerAssessment_01"
setwd(wd)
write.csv(training, file = "training.csv")
write.csv(crossVal, file = "crossVal.csv")
write.csv(dfTrain, file = "dfTraincsv")
write.csv(dfCross, file = "dfCross.csv")
write.csv(dfTrain, file = "dfTrain.csv")
write.csv(training, file = "training.csv")
write.csv(crossVal, file = "crossVal.csv")
write.csv(dfTrain, file = "dfTrain.csv")
write.csv(dfCross, file = "dfCross.csv")
NAColumnd
NAColumns
str(training)
modelFit_rf <- train(classe~ ., method = "rf", preProcess = "pca", data = dfTrain[1:30,], prox=TRUE)
modelFit_gbm <- train(classe ~ ., method="gbm",data=training[1:300,],verbose=FALSE)
modelFit_rf <- train(classe~ ., method = "rf", preProcess = "pca", data = dfTrain[1:300,], prox=TRUE)
modelFit_rf <- train(classe~ ., method = "rf", preProcess = "pca", data = dfTrain[1:1000,], prox=TRUE)
wd <- "C:/Users/jsardinha/Documents/GitHub/PML_JHU_PeerAssessment_01"
setwd(wd)
library(ggplot2)
library(lattice)
library(caret)
library(splines)
library(survival)
library(gbm)
library(randomForest)
library(plyr)
library(splines)
library(survival)
library(parallel)
library(iterators)
library(foreach)
library(doParallel)
modelFit_rf <- train(classe~ ., method = "rf", preProcess = "pca", data = training[1:1000,], prox=TRUE)
warnings()
data(iris); library(ggplot2)
library(caret)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit$finalModel
getTree(modFit$finalModel, k=2)
rfModel <- train(classe ~ ., data=dfTrain, method="rf", prox=TRUE)
install.packages('e1071', dependencies=TRUE)
2+2
install.packages("e1071", dependencies = TRUE)
